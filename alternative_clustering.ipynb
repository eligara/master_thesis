{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import os\n",
    "from hsbmpy import get_file, define_labels, get_cluster_given_l\n",
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 2\n",
    "#setup = 'oversigma_10tissue'\n",
    "#label = 'disease_type'\n",
    "label='primary_site'\n",
    "#label = 'uniq'\n",
    "L = 4\n",
    "#labels = ['primary_site', 'disease_type']\n",
    "#labels = ['primary_site', 'secondary_site']\n",
    "#directory = \"results/hSBM/%s\"%setup\n",
    "#directory=\"gtex/hsbm/%s\"%setup\n",
    "directory=\"/Volumes/GoogleDrive/My Drive/tesi_magistrale/tesi/gtex/hsbm/oversigma_10tissue\"\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mainTable.csv\", index_col=[0], header=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clustersizes.txt\",'r') as f:\n",
    "    xl = np.array(f.read().split(sep='\\n'))[:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "dend = shc.dendrogram(shc.linkage(df.T.values, method='ward'), leaf_rotation=90., leaf_font_size=8.,)\n",
    "plt.xlabel(\"samples\", fontsize=16)\n",
    "plt.show()\n",
    "fig.savefig(\"hierarchical_dendogram.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_csv(\"files.dat\", index_col=[0])\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores['hierarchical']={\n",
    "    'h':[],\n",
    "    'c':[],\n",
    "    'V':[]\n",
    "}\n",
    "for x in xl:\n",
    "    print(\"testing with %d clusters\"%x)\n",
    "    cluster = AgglomerativeClustering(n_clusters=x, affinity='euclidean', linkage='ward')  \n",
    "    out = cluster.fit_predict(df.T.values)\n",
    "    true_out = []\n",
    "    for sample in df.columns.values:\n",
    "        try:\n",
    "            true_out.append(get_file(sample, df_files)['primary_site'])\n",
    "        except:\n",
    "            true_out.append('')\n",
    "    score = (homogeneity_completeness_v_measure(true_out, out))\n",
    "    scores['hierarchical']['h'].append(score[0])\n",
    "    scores['hierarchical']['c'].append(score[1])\n",
    "    scores['hierarchical']['V'].append(score[2])\n",
    "    \n",
    "pd.DataFrame(data=scores['hierarchical']).to_csv(\"hierarchical.scores\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topicsizes.txt\",'r') as f:\n",
    "    tl = np.array(f.read().split(sep='\\n'))[:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['lda']={\n",
    "    'h':[],\n",
    "    'c':[],\n",
    "    'V':[]\n",
    "}\n",
    "totalobjcets = len(df.columns)\n",
    "for l,x in enumerate(xl[::-1]):\n",
    "    #lda\n",
    "    print(\"lda\")\n",
    "    ntopic = tl[l]\n",
    "    lda = LatentDirichletAllocation(n_components=ntopic, random_state=42, n_jobs=2)\n",
    "    topics = lda.fit_transform(df.T.values)\n",
    "    \n",
    "    #save topic distr\n",
    "    print(\"saving topic-distr\")\n",
    "    df_topic_distr = pd.DataFrame(data=topics, columns=[\"Topic %d\"%(t+1) for t in np.arange(tl[l])])\n",
    "    df_topic_distr.insert(0,'i_doc',np.arange(len(df.columns)))\n",
    "    df_topic_distr.insert(1,'doc',df.columns)\n",
    "    df_topic_distr.to_csv(\"lda/lda_level_%d_topic-dist.csv\"%l, index=False, header=True)\n",
    "    \n",
    "    #save clusters\n",
    "    print(\"saving clusters\")\n",
    "    df_clusters = pd.DataFrame(index=np.arange(totalobjcets))\n",
    "    cluster = AgglomerativeClustering(n_clusters=x, affinity='euclidean', linkage='ward')  \n",
    "    out = cluster.fit_predict(topics)\n",
    "    \n",
    "    for c in np.arange(out.max()+1)[::-1]:\n",
    "        c_objects = df.columns[np.argwhere(out==c)].values.T[0]\n",
    "        df_clusters.insert(0,\"Cluster %d\"%(c+1),np.concatenate((c_objects,[np.nan for _ in np.arange(totalobjcets-len(c_objects))])))\n",
    "    df_clusters.dropna(axis=0,how='all', inplace=True)\n",
    "    df_clusters.to_csv(\"lda/lda_level_%d_clusters.csv\"%(l), index=False, header=True)\n",
    "    \n",
    "    #metrics\n",
    "    print(\"saving metrics\")\n",
    "    true_out = []\n",
    "    for sample in df.columns.values:\n",
    "        try:\n",
    "            true_out.append(get_file(sample, df_files)['primary_site'])\n",
    "        except:\n",
    "            true_out.append('')\n",
    "    score = (homogeneity_completeness_v_measure(true_out, out))\n",
    "    scores['lda']['h'].append(score[0])\n",
    "    scores['lda']['c'].append(score[1])\n",
    "    scores['lda']['V'].append(score[2])\n",
    "    break\n",
    "pd.DataFrame(data=scores['lda']).to_csv(\"%s/lda.scores\"%directory, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
