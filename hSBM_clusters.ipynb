{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from matplotlib import pyplot as plt\n",
    "from TCGA_files import *\n",
    "#from ensembleAPI import geneinfo, genesinfo\n",
    "from IPython.display import HTML\n",
    "from sklearn import metrics\n",
    "from hsbmpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, hsbmpy\n",
    "importlib.reload(hsbmpy)\n",
    "from hsbmpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 3\n",
    "#setup='highlyvariable_7tissues'\n",
    "setup = 'oversigma_10tissue'\n",
    "#label = 'disease_type'\n",
    "label='primary_site'\n",
    "#label = 'uniq'\n",
    "L = 4\n",
    "#labels = ['primary_site', 'disease_type', 'uniq']\n",
    "labels = ['primary_site', 'secondary_site']\n",
    "#directory = \"results/hSBM/%s\"%setup\n",
    "directory=\"gtex/hsbm/%s\"%setup\n",
    "df_clusters = pd.read_csv(\"%s/topsbm/topsbm_level_%d_clusters.csv\"%(directory,L), header=[0])\n",
    "df_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_csv(\"/Users/filippo/Developer/tesi/gtex/files.dat\", index_col=[0], header=[0])\n",
    "#df_files = pd.read_csv(\"/Users/filippo/Developer/tesi/results/counts/files.dat\", index_col=[0], header=[0])\n",
    "#df_files.insert(2,'uniq', '')\n",
    "#for sample in df_files.index.values:\n",
    "#    row = df_files.loc[sample,:]\n",
    "#    df_files.at[sample,'uniq']='%s[%s]'%(row['primary_site'],row['disease_type'])\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise=True\n",
    "level=2\n",
    "cluster = get_cluster_given_l(level, directory)\n",
    "fraction_sites = get_fraction_sites(cluster,df_files=df_files,label='primary_site', normalise=normalise)\n",
    "fraction_sites_shuffle = get_fraction_sites(cluster, pd.read_csv(\"%s/files.dat.shuf\"%directory, index_col=[0]), normalise=normalise)\n",
    "clustersinfo_shuffle = get_clustersinfo(cluster, fraction_sites_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersinfo = get_clustersinfo(cluster,fraction_sites)\n",
    "plot_cluster_composition(fraction_sites,directory,level,label='uniq', normalise=normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    for level in np.arange(L+1)[::-1]:\n",
    "        normalise = True\n",
    "        cluster = get_cluster_given_l(level, directory)\n",
    "        fraction_sites = get_fraction_sites(cluster,df_files=df_files,label=label, normalise=normalise)\n",
    "        clustersinfo = get_clustersinfo(cluster,fraction_sites)\n",
    "        plot_cluster_composition(fraction_sites,directory,level,label=label, normalise=normalise)\n",
    "        make_heatmap(fraction_sites, directory, label, level, normalise=normalise)\n",
    "        \n",
    "        normalise = False\n",
    "        cluster = get_cluster_given_l(level, directory)\n",
    "        fraction_sites = get_fraction_sites(cluster,df_files=df_files,label=label, normalise=normalise)\n",
    "        clustersinfo = get_clustersinfo(cluster,fraction_sites)            \n",
    "        plot_maximum(clustersinfo,cluster,label,level, directory)\n",
    "        plot_maximum_size(clustersinfo,label,level, directory)\n",
    "        plot_maximum_label(clustersinfo,label,level, directory)\n",
    "        try:\n",
    "            fraction_sites_shuffle = get_fraction_sites(cluster, pd.read_csv(\"%s/files.dat.shuf\"%directory, index_col=[0]), normalise=normalise)\n",
    "            clustersinfo_shuffle = get_clustersinfo(cluster, fraction_sites_shuffle)\n",
    "            plot_cluster_composition(fraction_sites_shuffle,directory,level, normalise=False, label=label, shuffled=True)\n",
    "            plot_maximum(clustersinfo,cluster,label,level,directory,clustersinfo_shuffle)\n",
    "            plot_maximum_size(clustersinfo,label,level, directory,clustersinfo_shuffle)\n",
    "            plot_maximum_label(clustersinfo,label,level, directory,clustersinfo_shuffle)\n",
    "            plot_labels_size(clustersinfo,label,level, directory,clustersinfo_shuffle)\n",
    "        except:\n",
    "            print(\"must shuffle files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for label in labels:\n",
    "    scores[label]={\n",
    "        'h':[],\n",
    "        'c':[],\n",
    "        'V':[]\n",
    "    }\n",
    "    for l in np.arange(L+1):\n",
    "        print(l)\n",
    "        true_labels, predicted_labels = define_labels(get_cluster_given_l(l, directory), df_files, label=label)\n",
    "        scores[label]['h'].append(metrics.cluster.homogeneity_score(true_labels, predicted_labels))\n",
    "        scores[label]['c'].append(metrics.cluster.completeness_score(true_labels, predicted_labels))\n",
    "        scores[label]['V'].append(metrics.cluster.v_measure_score(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['shuffle']={\n",
    "        'h':[],\n",
    "        'c':[],\n",
    "        'V':[]\n",
    "    }\n",
    "for l in np.arange(1,L+1):\n",
    "    print(l)\n",
    "    _, predicted_labels = define_labels(get_cluster_given_l(l, directory), df_files, label='primary_site')\n",
    "    true_labels, _ = define_labels(get_cluster_given_l(l,directory), pd.read_csv(\"%s/files.dat.shuf\"%directory, index_col=[0]),label='primary_site')\n",
    "    scores['shuffle']['h'].append(metrics.cluster.homogeneity_score(true_labels, predicted_labels))\n",
    "    scores['shuffle']['c'].append(metrics.cluster.completeness_score(true_labels, predicted_labels))\n",
    "    scores['shuffle']['V'].append(metrics.cluster.v_measure_score(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['hierarchical']={'h': [0.9999999999999997,\n",
    "   0.9944332047037256,\n",
    "   0.9642105604410879,\n",
    "   0.4116961952184678],\n",
    "  'c': [0.08925049268913182,\n",
    "   0.12613583938380396,\n",
    "   0.22573696031830276,\n",
    "   0.16648964926015783],\n",
    "  'V': [0.16387505589975176,\n",
    "   0.22387494576663095,\n",
    "   0.3658278322759565,\n",
    "   0.23709731325391545]}\n",
    "scores['lda']={'h': [0.9999999999999997,\n",
    "  0.9969891871685275,\n",
    "  0.9872026855086575,\n",
    "  0.9184599667078042],\n",
    " 'c': [0.08925049268913182,\n",
    "  0.116700530320663,\n",
    "  0.18807432116559844,\n",
    "  0.3164133490502569],\n",
    " 'V': [0.16387505589975176,\n",
    "  0.20894359540077767,\n",
    "  0.315955257995372,\n",
    "  0.470676611642876]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_score_lines(ax, scores, labels, xl):\n",
    "    init_metric_plot(ax,xl)\n",
    "    colors = {\n",
    "        'primary_site':'blue',\n",
    "        'secondary_site':'red',\n",
    "        'disease_type':'red',\n",
    "        'shuffle': 'orange',\n",
    "        'uniq':'purple',\n",
    "        'hierarchical':'cyan',\n",
    "        'lda':'violet'\n",
    "    }\n",
    "    for label in labels:\n",
    "        ax.plot(xl, scores[label]['h'], ls='-.', c=colors[label], alpha=0.2)\n",
    "        ax.plot(xl, scores[label]['c'], ls=':', c=colors[label], alpha=0.2)\n",
    "        ax.plot(xl, scores[label]['V'], label='MI - %s'%label, ls='-', c=colors[label])\n",
    "    customize_metric_plot(ax,xl)\n",
    "        \n",
    "def customize_metric_plot(ax, xl):\n",
    "    ax.set_xlabel(\"number of clusters\", fontsize=16)\n",
    "    ax.set_ylabel(\"score\", fontsize=16)\n",
    "    ax.set_ylim((0,1.1))\n",
    "    ax.set_xlim(np.min(xl)-1,np.max(xl))\n",
    "    ax.set_xscale('log')\n",
    "    ax.legend(loc='best', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = [len(get_cluster_given_l(li,directory)) for li in np.linspace(1,L,L)]\n",
    "fig=plt.figure(figsize=(10,6))\n",
    "ax = fig.subplots(1)\n",
    "add_score_lines(ax,scores,labels,xl)\n",
    "h = np.array(scores['primary_site']['h'])\n",
    "c = np.array(scores['secondary_site']['c'])\n",
    "ax.plot(xl, 2*h*c/(h+c), ls='-',c='g')\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores.pdf\"%(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,6))\n",
    "ax = fig.subplots(1)\n",
    "add_score_lines(ax,scores,np.concatenate((labels,['shuffle'])),xl)\n",
    "h = np.array(scores['primary_site']['h'])\n",
    "c = np.array(scores['secondary_site']['c'])\n",
    "ax.plot(xl, 2*h*c/(h+c), ls='-',c='g')\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores_shuffle.pdf\"%(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,6))\n",
    "ax = fig.subplots(1)\n",
    "add_score_lines(ax,scores,np.concatenate((labels,['shuffle','hierarchical'])),xl)\n",
    "h = np.array(scores['primary_site']['h'])\n",
    "c = np.array(scores['secondary_site']['c'])\n",
    "ax.plot(xl, 2*h*c/(h+c), ls='-',c='g')\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores_hier.pdf\"%(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,6))\n",
    "ax = fig.subplots(1)\n",
    "add_score_lines(ax,scores,scores.keys(),xl)\n",
    "h = np.array(scores['primary_site']['h'])\n",
    "c = np.array(scores['secondary_site']['c'])\n",
    "ax.plot(xl, 2*h*c/(h+c), ls='-',c='g')\n",
    "plt.show()\n",
    "fig.savefig(\"%s/metric_scores_all.pdf\"%(directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for c in cluster:\n",
    "    print(c)\n",
    "    for sample in cluster[c]:\n",
    "        #true_labels.append(getFile(sample)['primary_site'].values[0])\n",
    "        try:\n",
    "            true_labels.append(df_files.loc[sample][label])\n",
    "            predicted_labels.append(c)\n",
    "        except:\n",
    "            print(\"error in %s\"%sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels_true = np.unique(true_labels,return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_metrics=pd.Series(name=setup+'__level_%d_%s'%(level,label))\n",
    "series_metrics['MI']=metrics.cluster.normalized_mutual_info_score(labels_true, predicted_labels, average_method='arithmetic')\n",
    "series_metrics['Homogeneity']=metrics.cluster.homogeneity_score(labels_true, predicted_labels) \n",
    "series_metrics['Completness']=metrics.cluster.completeness_score(labels_true, predicted_labels) \n",
    "series_metrics['Vmeasure']=metrics.cluster.v_measure_score(labels_true, predicted_labels)\n",
    "series_metrics['Fowlkes-Mallows']=metrics.cluster.fowlkes_mallows_score(labels_true,predicted_labels)\n",
    "series_metrics['AdjustedRandIndex']=metrics.cluster.adjusted_rand_score(labels_true,predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metrics = pd.DataFrame(columns=['AdjustedRandIndex','MI','Homogeneity','Completness','Vmeasure','Fowlkes-Mallows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_metrics.append(series_metrics, ignore_index=False, verify_integrity=True).to_csv(\"results/hSBM/metrics.csv\", index=True,header=True)\n",
    "except:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.read_csv(\"results/hSBM/metrics.csv\", index_col=[0],header=[0])\n",
    "df_metrics.sort_values(by=['MI','Homogeneity'], ascending=False, axis=0, inplace=True)\n",
    "df_metrics.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 20)) # set size frame\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "tabla = pd.plotting.table(ax, df_metrics.round(decimals=2), loc='upper right', colWidths=[0.12]*len(df_metrics.columns))  # where df is your data frame\n",
    "tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "tabla.scale(1, 2) # change size table\n",
    "plt.savefig('results/hSBM/metrics.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.cluster.contingency_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files[df_files['primary_site']=='Brain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
